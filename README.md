[README (2).md](https://github.com/user-attachments/files/22651463/README.2.md)
# ğŸš€ SpaceX Falcon 9 First Stage Landing Prediction

## ğŸ“‹ Sobre o Projeto

Este projeto implementa um pipeline de Machine Learning para prever se o primeiro estÃ¡gio do foguete Falcon 9 da SpaceX irÃ¡ pousar com sucesso. Esta informaÃ§Ã£o Ã© crucial para estimar o custo de lanÃ§amento, jÃ¡ que a SpaceX anuncia lanÃ§amentos por $62 milhÃµes (comparado a mais de $165 milhÃµes de outras empresas), sendo a economia possÃ­vel devido Ã  reutilizaÃ§Ã£o do primeiro estÃ¡gio.

## ğŸ¯ Objetivos

- Realizar AnÃ¡lise ExploratÃ³ria de Dados
- Criar coluna de classificaÃ§Ã£o (Class)
- Padronizar os dados
- Dividir em dados de treino e teste
- Encontrar os melhores hiperparÃ¢metros para:
  - Logistic Regression
  - Support Vector Machine (SVM)
  - Decision Tree
  - K-Nearest Neighbors (KNN)
- Determinar qual mÃ©todo performa melhor

## ğŸ“Š Dataset

- **Total de registros:** 90 lanÃ§amentos
- **Features:** 83 colunas apÃ³s one-hot encoding
- **DivisÃ£o:** 80% treino (72 amostras) / 20% teste (18 amostras)
- **VariÃ¡vel target:** Class (0 = falha no pouso, 1 = pouso bem-sucedido)

### Principais Features

- FlightNumber
- PayloadMass
- Orbit (LEO, GTO, ISS, etc.)
- LaunchSite (CCAFS, VAFB, KSC)
- GridFins, Reused, Legs
- Block, ReusedCount
- Serial do Booster
- Coordenadas geogrÃ¡ficas

## ğŸ”§ Tecnologias Utilizadas

```python
- Python 3.8
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn (preprocessing, GridSearchCV, train_test_split)
```

## ğŸ§ª Metodologia

### 1. PrÃ©-processamento
- StandardizaÃ§Ã£o dos dados usando `StandardScaler`
- DivisÃ£o treino/teste: 80/20 com `random_state=2`

### 2. OtimizaÃ§Ã£o de HiperparÃ¢metros
UtilizaÃ§Ã£o de `GridSearchCV` com **10-fold cross-validation** para todos os modelos.

## ğŸ“ˆ Resultados

### ğŸ† Desempenho dos Modelos

| Modelo | Accuracy (Teste) | Best Parameters |
|--------|------------------|-----------------|
| **Logistic Regression** | **83.33%** | C: 0.01, penalty: 'l2', solver: 'lbfgs' |
| **Support Vector Machine** | **83.33%** | C: 1.0, gamma: 0.0316, kernel: 'sigmoid' |
| **K-Nearest Neighbors** | **83.33%** | n_neighbors: 10, algorithm: 'auto', p: 1 |
| Decision Tree | 72.22% | criterion: 'entropy', max_depth: 16, min_samples_leaf: 2 |

### ğŸ“Š Melhores Resultados por Modelo

#### Logistic Regression
```
Tuned hyperparameters (best parameters): {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}
Accuracy: 0.8333333333333334
Validation Score: 0.8464285714285713
```

#### Support Vector Machine (SVM)
```
Tuned hyperparameters (best parameters): {'C': 1.0, 'gamma': 0.03162277660168379, 'kernel': 'sigmoid'}
Accuracy: 0.8333333333333334
```

#### K-Nearest Neighbors (KNN)
```
Tuned hyperparameters (best parameters): {'algorithm': 'auto', 'n_neighbors': 10, 'p': 1}
Accuracy: 0.8333333333333334
```

#### Decision Tree
```
Tuned hyperparameters (best parameters): {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'splitter': 'random'}
Accuracy: 0.7222222222222222
```

## ğŸ¯ ConclusÃµes

1. **TrÃªs modelos empatados:** Logistic Regression, SVM e KNN alcanÃ§aram a mesma acurÃ¡cia de **83.33%** no conjunto de teste.

2. **Decision Tree teve menor desempenho:** Com apenas 72.22% de acurÃ¡cia, indicando possÃ­vel overfitting ou complexidade inadequada para o dataset.

3. **Modelos mais simples performaram melhor:** A RegressÃ£o LogÃ­stica com regularizaÃ§Ã£o L2 baixa (C=0.01) foi suficiente para atingir o melhor resultado.

4. **Dataset pequeno:** Com apenas 18 amostras de teste, a margem de erro Ã© alta. Mais dados seriam necessÃ¡rios para validaÃ§Ã£o robusta.

## ğŸ’¡ RecomendaÃ§Ãµes

- Para produÃ§Ã£o, considerar **ensemble** dos trÃªs melhores modelos
- Coletar mais dados de lanÃ§amentos para melhorar a generalizaÃ§Ã£o
- Implementar validaÃ§Ã£o cruzada estratificada para datasets pequenos
- Explorar feature engineering adicional (interaÃ§Ãµes entre variÃ¡veis)

## ğŸ“ Estrutura do CÃ³digo

```
â”œâ”€â”€ Data Loading & Exploration
â”œâ”€â”€ Feature Engineering (One-Hot Encoding)
â”œâ”€â”€ Data Preprocessing (Standardization)
â”œâ”€â”€ Train-Test Split
â”œâ”€â”€ Model Training & Hyperparameter Tuning
â”‚   â”œâ”€â”€ Logistic Regression
â”‚   â”œâ”€â”€ Support Vector Machine
â”‚   â”œâ”€â”€ Decision Tree
â”‚   â””â”€â”€ K-Nearest Neighbors
â”œâ”€â”€ Model Evaluation
â””â”€â”€ Results Comparison
```

## ğŸ‘¤ Autor

**jrFrancesco**

## ğŸ“„ LicenÃ§a

Este projeto faz parte do curso IBM Data Science da Skills Network.

---

**â±ï¸ Tempo estimado:** 60 minutos  
**ğŸ“ NÃ­vel:** IntermediÃ¡rio  
**ğŸ“š Curso:** IBM Data Science Professional Certificate
